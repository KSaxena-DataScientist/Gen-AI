{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Import langchain modules\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found in .env file.\")\n",
    "\n",
    "# Set the OpenAI API key in the environment\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\himan\\Downloads\\Attention is all you need.pdf\"\n",
    "\n",
    "# Helper function to replace tabs with spaces in texts\n",
    "def replace_t_with_space(texts):\n",
    "    \"\"\"\n",
    "    Replaces tab characters with spaces in the given texts.\n",
    "    \"\"\"\n",
    "    for text in texts:\n",
    "        if hasattr(text, 'page_content'):\n",
    "            text.page_content = text.page_content.replace('\\t', ' ')\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the PDF into a vector store\n",
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF document into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded document content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the PDF and create the vector store\n",
    "chunks_vector_store = encode_pdf(path)\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Test query\n",
    "test_query = \"What is the summary of paper?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (5.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\himan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pypdf) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\himan\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the PDF and create the vector store\n",
    "chunks_vector_store = encode_pdf(path)\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Test query\n",
    "test_query = \"What is the summary of paper?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "networks. In Advances in Neural Information Processing Systems , pages 3104–3112, 2014.\n",
      "[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\n",
      "Rethinking the inception architecture for computer vision. CoRR , abs/1512.00567, 2015.\n",
      "[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\n",
      "Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\n",
      "translation system: Bridging the gap between human and machine translation. arXiv preprint\n",
      "arXiv:1609.08144 , 2016.\n",
      "[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\n",
      "fast-forward connections for neural machine translation. CoRR , abs/1606.04199, 2016.\n",
      "11\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "\n",
      "convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\n",
      "the approach we take in our model.\n",
      "As side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\n",
      "from our models and present and discuss examples in the appendix. Not only do individual attention\n",
      "heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\n",
      "and semantic structure of the sentences.\n",
      "5 Training\n",
      "This section describes the training regime for our models.\n",
      "5.1 Training Data and Batching\n",
      "We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\n",
      "sentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\n",
      "target vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\n",
      "2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to retrieve context based on a query\n",
    "def retrieve_context_per_question(query, retriever):\n",
    "    \"\"\"\n",
    "    Retrieves relevant documents for the given query using the provided retriever.\n",
    "    \"\"\"\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    return relevant_docs\n",
    "\n",
    "# Retrieve context based on the query\n",
    "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
    "\n",
    "# Helper function to display the retrieved context\n",
    "def show_context(context):\n",
    "    \"\"\"\n",
    "    Displays the content of the retrieved documents.\n",
    "    \"\"\"\n",
    "    for i, doc in enumerate(context):\n",
    "        print(f\"Document {i+1}:\\n\")\n",
    "        print(doc.page_content)\n",
    "        print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Display the retrieved context\n",
    "show_context(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
